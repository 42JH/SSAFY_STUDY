# [Algorithm Deep Dive] 재귀와 완전탐색: 무한을 다루는 기술

> **"무식하게 푸는 것이 가장 강력할 때가 있다."**
> 컴퓨터의 연산 능력을 극대화하여 정답을 찾아내는 **완전탐색(Exhaustive Search)**과 그 기반이 되는 **재귀(Recursion)**, 그리고 공간을 탐색하는 **DFS/BFS**에 대해 심층적으로 탐구한다.

---

## 1. 재귀 (Recursion): 자기 참조의 미학과 스택의 시각화

재귀는 단순한 프로그래밍 기법이 아니라 **문제를 정의하는 철학**이다. 큰 문제를 해결하기 위해 자신과 동일한 형태의 더 작은 문제를 해결하는 방식을 의미한다.

### 🏛️ [역사적 배경] 수학적 귀납법과 유클리드
*   **수학적 귀납법 (Mathematical Induction)**: 재귀 알고리즘의 논리적 정당성은 수학적 귀납법에 뿌리를 둔다.
    1.  **Base Case**: $N=1$일 때 성립함을 증명한다. (재귀의 종료 조건)
    2.  **Inductive Step**: $N=k$일 때 성립한다고 가정하면, $N=k+1$일 때도 성립함을 증명한다. (재귀 호출)
*   **인류 최초의 알고리즘**: 기원전 300년경 유클리드의 **최대공약수(GCD)** 알고리즘(유클리드 호제법)은 재귀적 구조를 가진 가장 오래된 알고리즘 중 하나다.
    $$GCD(A, B) = GCD(B, A \% B)$$

### 🛠️ [실전 심화] 재귀 함수 설계의 3단계 공식
코딩 테스트에서 재귀 함수를 작성할 때는 다음 3단계 프로세스를 기계적으로 따르는 것이 좋다.

1.  **상태(State) 정의**: 함수의 인자로 무엇을 넘길 것인가?
    *   도르마무처럼 반복되는 루프 속에서 **변해야 하는 값**이 무엇인지 식별한다.
    *   예: `dfs(index, current_sum, visited)`
2.  **종료 조건(Base Case)**: 언제 멈출 것인가?
    *   재귀의 가장 첫 줄에 작성한다.
    *   정답을 찾은 경우(성공)와 더 이상 갈 곳이 없는 경우(실패/범위 초과)를 모두 처리해야 한다.
3.  **점화식(Recurrence)**: 다음 단계로 어떻게 넘어갈 것인가?
    *   문제를 더 작은 단위로 쪼개어 자기 자신을 호출한다.
    *   **"믿음의 도약(Leap of Faith)"**: `solve(n-1)`이 알아서 잘 해결해 줄 것이라고 믿고, 나는 현재 단계의 연산만 수행한다.

---

## 2. 완전탐색 (Exhaustive Search): 모든 가능성의 나열

### 🏛️ [역사적 배경] 핑갈라의 발견
보통 이진법이나 조합론은 서양 수학의 산물로 여겨지나, 기원전 3세기 인도의 학자 **핑갈라(Pingala)**는 시의 운율을 분석하며 이진법 체계와 조합론적 생성 방법(**메루 프라스타라**)을 이미 정립하였다. 이는 모든 패턴을 빠짐없이 나열하려는 시도가 인류 지성사의 매우 오래된 주제임을 시사한다.

### 🛠️ [실전 심화] 순열/조합 구현의 정석 (Library vs Backtracking)
완전탐색 문제를 만났을 때 선택할 수 있는 두 가지 강력한 무기가 있다.

1.  **Python의 축복: `itertools`**
    *   단순히 순열/조합을 생성하여 순회하는 경우, **무조건 라이브러리를 사용한다.** C언어로 최적화되어 있어 직접 구현한 코드보다 훨씬 빠르다.
    *   `permutations`: 순서 O (줄 세우기)
    *   `combinations`: 순서 X (팀 뽑기)

2.  **백트래킹 (Backtracking) 템플릿**: 조건에 따라 가지치기가 필요한 경우
    ```python
    def backtrack(path, visited):
        # 1. Base Case: 정답을 찾았거나 깊이 제한 도달
        if len(path) == target_length:
            result.append(path[:]) # Deep Copy 필수!
            return

        for i in range(len(choices)):
            if not visited[i]:
                # 2. Try (상태 변경)
                visited[i] = True
                path.append(choices[i])
                
                # 3. Recurse (다음 단계)
                backtrack(path, visited)
                
                # 4. Restore (상태 복구 - Backtracking 핵심)
                path.pop()
                visited[i] = False
    ```
    > **Tip**: `path`를 결과에 담을 때 `path[:]`나 `list(path)`로 복사해서 넣지 않으면, 나중에 빈 리스트만 남게 된다.

---

## 3. 그래프 탐색: 공간을 지배하는 법 (DFS/BFS)

### 🏛️ [역사적 배경] 전설적인 두 문제
*   **쾨니히스베르크의 다리 (오일러, 1736)**: 연결된 공간의 특성을 점(Vertex)과 선(Edge)으로 추상화하여 **위상수학(Topology)**과 그래프 이론을 창시하였다. "홀수차수 점"의 개수가 한붓그리기 가능 여부를 결정함을 증명하였다.
*   **트레모의 알고리즘 (19세기)**: 미로 탐색 시 "지나온 길을 표시(Marking)"하고 막히면 되돌아가는(Backtracking) 현대 **DFS**의 원형을 고안하였다.

### 🛠️ [실전 심화 1] 격자(Grid) 탐색의 필승 패턴
코딩 테스트 단골 문제인 '미로 찾기', '영역 넓히기' 등 2차원 배열 문제는 다음 패턴으로 정복한다.

1.  **방향 벡터(Direction Vectors) 사용**:
    *   4방향(상하좌우)을 `if`문 4개로 처리하면 코드가 복잡해진다. `dx, dy` 리스트를 활용한다.
    ```python
    dx = [-1, 1, 0, 0] # 상하좌우
    dy = [0, 0, -1, 1]
    
    for i in range(4):
        nx, ny = x + dx[i], y + dy[i]
        # 범위 체크 (필수)
        if 0 <= nx < N and 0 <= ny < M:
            # 방문 여부 및 조건 체크
            if not visited[nx][ny] and grid[nx][ny] == 1:
                ...
    ```

2.  **BFS와 최단 거리**:
    *   가중치가 없는 그래프(모든 간선 비용이 1)에서 최단 거리는 **무조건 BFS**다.
    *   `collections.deque`를 사용하여 $O(1)$로 넣고 뺀다. `list.pop(0)`은 $O(N)$이라 시간 초과 발생!

### 🛠️ [실전 심화 2] 3가지 고급 그래프 패턴

#### 1. 거리 배열 (Distance Array)
단순히 `visited = [True/False]`만 기록하면 "몇 번 만에 도착했는지" 알 수 없다.
*   `dist` 배열을 `-1`로 초기화하고, 방문할 때마다 `dist[next] = dist[current] + 1`을 기록한다.
*   이는 미로 최단 거리 문제의 정석 풀이법이다.

#### 2. 연결 요소 (Connected Components)
"섬의 개수를 구하시오" 같은 문제 유형이다.
*   이중 `for`문으로 격자의 모든 점을 순회하며, 방문하지 않은 점(`!visited`)을 만날 때마다 BFS/DFS를 시작한다.
*   호출 횟수가 곧 섬의 개수(Component Count)가 된다.

#### 3. 다중 시작점 BFS (Multiple Sources)
"토마토가 여러 군데에서 동시에 익기 시작한다면?"
*   모든 시작점(익은 토마토)을 **탐색 시작 전에 미리 큐(Queue)에 다 넣고** BFS를 돌린다.
*   마치 여러 곳에서 동시에 물결이 퍼지는 효과를 낼 수 있다.

---

## 4. 동적 계획법 (Dynamic Programming): 기억의 기술

### 🏛️ [역사적 배경] 벨만의 연구비 사수 작전
1950년대 **리처드 벨만**은 국방부 장관 찰스 윌슨의 기초 연구 예산 삭감을 피하기 위해 전략적인 작명을 했다. 'Dynamic'은 "역동적인, 활동적인" 느낌을 주고, 'Programming'은 당시 군대에서 "계획, 스케줄링"을 의미했으므로, 누구도 반대하기 힘든 완벽한 이름이었다. 본질은 **"문제를 나누어 풀고 결과를 저장한다"**는 수학적 최적화 기법이다.

### 🛠️ [실전 심화 1] DP의 핵심: 상태 정의(State Definition) 훈련
DP 문제 풀이의 90%는 **"$dp[i]$를 무엇으로 정의할 것인가?"**에서 판가름 난다. 자주 나오는 패턴을 익혀두자.

1.  **1차원 선형 DP**:
    *   `dp[i]`: $i$번째 계단까지 올랐을 때의 최대 점수.
    *   `dp[i]`: $i$원을 만들기 위한 최소 동전 개수.
2.  **최장 증가 부분 수열 (LIS)**:
    *   `dp[i]`: $i$번째 원소를 **마지막(끝)으로 하는** 부분 수열 중 가장 긴 길이.
    *   이중 루프를 사용하며, 자신보다 작은 이전 원소들의 DP 값 중 최댓값에 +1을 한다.
3.  **2차원 격자/배낭**:
    *   `dp[i][j]`: $(i, j)$ 좌표까지 오는 경로의 수.
    *   `dp[i][w]`: $i$번째 물건까지 고려하고 배낭 무게가 $w$일 때의 최대 가치.

### 🛠️ [실전 심화 2] DP 2대장 패턴 정복

#### 1. LCS (최장 공통 부분 수열)
두 문자열 `ACAYKP`와 `CAPCAK`의 공통 부분 중 가장 긴 것을 찾으라.
*   `dp[i][j]`: 문자열 A의 $i$번째, B의 $j$번째까지 비교했을 때의 LCS 길이.
*   **문자가 같으면**: 대각선 위 값 + 1 (`dp[i-1][j-1] + 1`)
*   **문자가 다르면**: 위쪽 값과 왼쪽 값 중 큰 것 (`max(dp[i-1][j], dp[i][j-1])`)

#### 2. 동전 교환 문제 (Coin Change)
$1, 2, 5$원 동전으로 15원을 만드는 **최소** 동전 개수는?
*   그리디(큰 동전부터)는 실패할 수 있다. (예: 1, 3, 4원으로 6원 만들기 $\rightarrow$ 그리디는 $4+1+1(3개)$, 최적은 $3+3(2개)$)
*   **DP 풀이**:
    *   `dp[i]`: $i$원을 만드는 최소 동전 수.
    *   점화식: $dp[i] = \min(dp[i], dp[i-\text{coin}] + 1)$
    *   작은 문제(작은 금액)의 최적해를 이용하여 큰 금액의 최적해를 보장한다.

---

## 5. [부록] 코딩 테스트 실전 전략 (Honey Tips)

### 🍯 1. 입력 크기(N)별 알고리즘 선택
*   **N ≤ 10**: $O(N!)$ 순열 탐색 가능. (Backtracking)
*   **N ≤ 20**: $O(2^N)$ 부분집합, 완전탐색 적합.
*   **N ≤ 1,000**: $O(N^2)$ **2차원 DP** 고려. (LIS, LCS, Knapsack)
*   **N ≤ 100,000**: $O(N \log N)$ 정렬 후 이분 탐색, 또는 **1차원 DP**. (Greedy, Topological Sort)

### 🍯 2. 주제별 체크리스트
*   **재귀**: 반드시 `sys.setrecursionlimit(10**6)` 설정. 기저 조건(Base Case) 먼저 작성.
*   **DFS vs BFS**:
    *   **최단 거리** = BFS (Queue)
    *   **경로의 특징/개수** = DFS (Recursion/Stack)
    *   **지도(Grid)** 문제 = 방향 벡터(`dx, dy`) 테크닉 사용.
*   **DP**: "경우의 수(Mod 연산)" 또는 "최대/최소" 문제. 점화식 수립이 어려우면 $N=1,2,3$ 손으로 써보기.
